ğŸ¤– Q&A Bot for YouTube Videos ğŸ¥

A Streamlit-powered application that lets you **ask questions** about the content of a YouTube video and get contextual answers, powered by Retrieval Augmented Generation (**RAG**) and embeddings.

![Demo](https://github.com/Kkoderr/q-a_bot/assets/merged.gif) 

---

âœ¨ Features
- ğŸ“œ **Automatic transcript extraction** from YouTube videos  
- ğŸ§© **Chunking & embeddings** to index video transcripts efficiently  
- ğŸ§  **RAG pipeline**: retrieves relevant transcript parts and generates answers  
- ğŸ–¼ **Streamlit UI**: clean interface to enter a video URL and ask questions  
- ğŸ§ª Supports free, local embedding models (no paid APIs needed)

---

âš™ï¸ How it works
1. Enter a **YouTube video ID** or URL.
2. The app extracts the transcript (auto-generated or manual).
3. Transcript is split into chunks and embedded.
4. When you ask a question, relevant chunks are retrieved.
5. A language model answers your question using retrieved context.

---

ğŸš€ Quick start

1ï¸âƒ£ Clone the repo -
  bash:
  git clone https://github.com/Kkoderr/q-a_bot.git
  cd q-a_bot
  
2ï¸âƒ£ Create & activate virtual environment -
  bash:
  python -m venv .venv
  source .venv/bin/activate  # macOS/Linux
  # OR
  .venv\Scripts\activate     # Windows
  
3ï¸âƒ£ Install dependencies -
  bash:
  pip install -r requirements.txt

4ï¸âƒ£ Run the Streamlit app -
  bash:
  streamlit run app.py
  
  Then open http://localhost:8501 in your browser.

ğŸ“¦ Project structure

â”œâ”€â”€ app.py               # Streamlit front-end

â”œâ”€â”€ ragSys.py            # RAG logic (embedding, retrieval)

â”œâ”€â”€ bot.py               # Handles LLM call & prompt

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md

ğŸ”‘ API keys
If using external LLMs (e.g., Google Gemini, Cohere), create a .env file:
  COHERE_API_KEY=...
  GOOGLE_API_KEY=...
And load them in your code using:
  from dotenv import load_dotenv
  load_dotenv()

ğŸ§  Built with
- Streamlit â€“ web UI
- YouTube Transcript API â€“ extract transcripts
- LangChain â€“ RAG pipeline
- Free embedding models from Hugging Face

ğŸ“ To do / ideas
 - Add multi-language support
 - Improve chunking with semantic splitting
 - Cache transcripts & embeddings
 - Deploy on Hugging Face Spaces or Streamlit Community Cloud

ğŸ¤ Contributing
PRs, issues and suggestions are very welcome!
Please open an issue first to discuss what youâ€™d like to change.

ğŸ“„ License
This project is open source under the MIT License.

â­ï¸ Show your support
If you find this useful, please â­ï¸ the repo!
Happy hacking! âœ¨
